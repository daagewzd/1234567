第一章 绪论
时间序列预测是机器学习领域十分重要的研究课题之一，时间序列预测通过对一系列时间点上过去值的分析和建模来实现对未来变量值或观测值进行预测。神经网络理论上可以逼近任何非线性函数，是处理时间序列数据的理想算法和工具，可以用来开发更具鲁棒性和准确性的预测算法。本文主要致力于提高算法的预测精度和泛化性，研究神经网络在时间序列预测问题上的可拓展性和优势。
1.1研究背景及意义
1.1.1研究背景
随着社会的不断发展和科学技术的进步，各个行业和领域都在产生大量的数据。比如，基金的价格和股票的成交量，供应链中产品库存的变化，网络购物中某件商品的销量，大气污染防治中对污染物的检测，传染病如COVID-19的感染率预测等，在工业领域中人们研发出了各种各样的传感器将其安装在自动化系统上进行数据的检测，同时网络通信技术的发展更加方便了数据的传输和检测，因此产生了越来越多的数据需要得到分析和处理。这些数据按照一定的时间间隔依次、连续地产生，常常包含着丰富的信息。我们把这类数据称之为“时间序列”。
时间序列是指对同一现象观测或记录到的一组按时间顺序排列起来的统计数据[1]，通过对时间序列进行编制和分析，根据时间序列所反映出来的发展过程、方向和趋势，进行类推或延伸，借以预测下一段时间或以后若干年内可能达到的水平，这种方法称为时间序列预测技术。时间序列数据在当今社会中正在以海量的速度生成，因此大量的科学家对实践序列数据进行了研究和分析，常用的方法主要分为两种，即基于统计的传统预测方法和智能计算的方法，如指数平滑法、分解法、季节系数法和Box-Jenkins方法中的AR（Auto Regression）模型、MA（Moving Average）模型、ARMA（Auto Regressive Moving Average）模型ARIMA（Auto Regressive Integrated Moving Average）模型，由于传统方法形式简单且预测效果低，通常用于预测一般时间序列。然而，这些模型假设预测数据具有线性和平稳性的特性，这是对具有高灵敏度和长期不可预测性的复杂时间序列的过度简化方法。因此，复杂时间序列预测迫切需要更可靠的策略。
在过去的20年中，智能计算方法得到了快速发展，其中许多方法成功地应用于提高预测性能，包括人工神经网络（ANN）和支持向量机（SVM）等[11]。
ANN是由类似于大脑中的生物结构相互连接而成的复杂网络结构，这些生物结构构建了时间序列的过去值与其未来对应值之间的映射，因此能够以任意精度逼近任何连续的非线性多变量函数[12]，而无需关于时间序列的任何特定假设或先验知识，并成为预测[13]和控制[14]中的有效工具。
到目前为止，各种ANN被应用于复杂时间序列预测。这些实例包括但不限于反向传播（BP）神经网络[15]、递归神经网络[16]、多层感知器神经网络[17]、回波状态网络[2]、[18]、集成神经网络[19]和模糊神经网络（FNN）[20]。但是数据大爆炸的时代令时间序列的规模和复杂度在不断的提升，大多数时间序列数据是非平稳的，并且包含了噪声和漂移，因此如何更加有效的提升神经网络在时间序列预测方面的性能是当前课题的一个重要研究方向。
1.1.2研究意义
时间序列是按照时间排序的一组随机变量，它通常是在相等间隔的时间段内，依照给定的采样率对某种潜在过程进行观测的结果。现实生活中，在一系列时间点上观测数据是司空见惯的活动，在农业、商业、气象、军事和医疗等研究领域都包含大量的时间序列数据。总之，目前时间序列数据正以不可预测的速度几乎产生于现实生活中的每一个应用领域。
对于农业领域，粮食是人类生存的根本，国民经济的命脉。农业总产值是指以货币表现的农、林、牧、渔业全部产品的总量，它反映了一个国家或地区在一定时期内农业生产的总规模和总水平。鉴于总产值的绝对数没有剔除价格因素的影响，可比性较弱，常常采用农业总产值指数代替。农业总产值指数是指报告期农业总产值同基期农业总产值的比率，它是消除价格因素后的物量发展水平，反映了一个国家的农业增长水平。粮食产量和农业总产值指数受到自然和社会多方面因素的影响，具有较大时序动态变化特性，是典型的农业经济时间序列数据。粮食产量和农业总产值指数的准确预测对保证粮食安全、指导农业发展生产、维持社会稳定具有非常重要的意义。
在商业领域，企业要制定出正确的合理的经营决策，前提是要有对未来科学的、准确的预测。时间序列预测是以企业的历史数据、现在的发展过程为前提，以其理论方法和技术支持为基础去研究企业未来数据的变化。为经营策略的制定提供科学的方法和理念依据。预测结果越精确，企业制定出正确经营决策的可能性就越大。
企业要想提高市场竞争力，一方面要把握住现有的市场，另一方面也需要能够预知将来的市场，有良好的市场应变能力。时间序列预测就可以对未来市场需求的预估和判断。企业可以随时了解市场上各商品的供求变动情况及趋势的同时，及时把握住市场契机，正确地选择或调整生产经营方向，以次来提高市场竞争力。
企业生产经营活动的核心是提高经济效益，而经营计划是否可行直接关系着经济效益是否能够提高。时间序列预测除了在生产经营活动方面发挥重要作用之外，企业架构也对其有不同程度的需求。
在气象领域，时间序列预测有着重要的作用，古人立木为杆，通过观察太阳照射的影子的长度测定方位、时间、节气，并一次观测恒星的周期，早起的先民就是靠这种日晷划分出了二十四节气，对我国的农业生产有着极大的促进作用。此外在19世纪中后叶，德国药剂师兼天文学家施瓦贝通过对太阳的观察和记录发现了太阳黑子的活动周期为11年左右。现如今，人们对气象的观察更加的详细与全面，通过对天气数据的记录，人们可以实现对未来15天内天气情况的预测，并以此来指导人们的出行和活动。
在军事领域，人们通过过去的数据来预测未来的威胁、需求、战略等变量，这样可以帮助军事领导者提前做好应对措施，增强战略优势，提高军事效能和安全性。比如在军事行动中，军队通过不同情景下的沙盘推演来预测和规划未来的作战环境和事态，对军事决策有着重要的意义。
在医疗领域，人们通过对医学时间序列建模，可以推测某种疾病在未来的发展水平，对避免可能发生的病理损害有重要意义，通过对发病率和致病因子的统计可以为疾病预防策略的制定提供科学依据。同时对医院住院人数和医疗耗材用量的预测可以更好地促进医疗资源的配置，降低医院的运行成本。
1.2国内外研究现状
1.2.1 时间序列预测研究现状
由于数据大量的生成对时间序列数据的预测提出了更高的要求，国内外的学者开始对如何提升预测性能进行了研究，从20世纪20年代开始，越来越多的科学家利用数理统计学原理分析时间序列，研究的中心从对时间序列数据表面现象的总结转移到分析序列值内在的相关关系上，并开发了一类基于统计学的预测算法。
根据预测变量数量的不同，时间序列预测方法可以分为单变量预测法和多变量预测法。其中单变量预测是根据所给序列中过去的观测数据来预测将来的数据，而多变量预测是结合同一个系统内的其他变量来预测目标变量。
最早的时间序列预测方法为分解算法，该方法通过将负荷曲线按照时间段或者类别分解为若干个时间序列，在分别预测后将各负荷预测结果合成。在20世纪初期，经济学家就曾利用这种方法识别和控制商业周期，现代分解方法的原理发表于1920年，当时引进了趋势之比的概念，此后分解方法开始被学者广泛的使用。对于季节性数据分解方法是有效的，但是大多数时间序列数据并非是季节性循环的，因此该方法使用价值不大。
在上个世纪50年代末，Brown提出了指数平滑法来进行生产预测，Brown认为时间序列的态势具有稳定性和规则性，所以时间序列可被合理的顺势推延，在不舍弃历史数据的前提下，对离预测期较近的历史数据给予较大的权数，权数由近到远按指数规律递减。指数平滑法根据本期的实际值和预测值，并借助于平滑系数（α）进行加权平均计算，预测下一期的值。平滑模型的主要优点是使用简单，只需少量数据和计算时间，模型分量和参数对使用者具有较直观的含义，容易理解和控制等。但是由于缺乏模型辨识和诊断检验的客观程序，该方法常受到理论工作者的批评。
在1927年，一位杰出的英国统计学家G.U.Yule为了预测市场的变化提出了自回归（AR）模型，之后，英国天文学家、数学家G.T.Walker与1931年在进行印度大气规律分析时使用了移动平均（MA）模型和自回归移动平均（ARMA）模型。但是这些工作在当时并没有产生较大的影响，在之后很长一段时间内，移动平均算法没有更进一步的发展。直到1970年，由于美国统计学家Box和英国统计学家Jenkins的开拓性工作，ARIMA模型才开始成为人们研究的热门课题。Box和Jenkins在其共同的著作《Time Series Analysis: Forecasting and Control》一书中系统的阐述了ARIMA模型的识别、估计、检验及预测的原理和方法，这些内容如今被称为经典时间序列分析方法。该著作极大的促进了时间序列分析在各个行业的应用和发展，以至于Box-Jenkins模型几乎成为了ARIMA模型的代名词。ARIMA模型的优点是具有一般性，可以处理各种类型的数据。该模型在统计上是完善的，有牢固的理论基础，为时间序列提供了一种结构化的建模方法，这些优点使得ARIMA模型在学术界得到了广泛的应用。
以上模型主要适用于单变量、同方差的时间序列预测，在多变量、异方差的预测场合和非线性系统的时间序列分析中存在诸多局限，因此学者们开始对时间序列预测算法进行改进和发展。美国统计和计量经济学家R.F.Engle在1982年提出了自回归条件异方差（Auto Regressive Conditional Heteroskedasticity，ARCH）模型对英国的通货膨胀率进行研究，这与ARIMA模型可以相互补充。此后ARCH模型进一步发展对预测技术产生了深远的影响，Engle也因此获得了2003年的诺贝尔奖。Lilien等人于1985年提出了均值自回归条件异方差（ARCH-M）将条件方差作为风险度量考虑在内用于分析金融资产的收益率和波动率之间的关系。Bollerslev在1986年在原来ARCH方程的基础上加入了条件方差的自回归部分形成了广义自回归条件异方差模型（GARCH）。G.G.Rivera于1991年提出了半参数自回归条件异方差模型（Semiparametric ARCH），此后对基于统计学原理的时间序列预测算法的研究还在继续。
基于统计学的时间序列预测技术大多侧重于理论的研究，通常假设时间序列数据为平稳且规律的，但是大多数采集到的时间序列书籍既非平稳又不具有明显的规律，因此在实际应用中，传统的时间序列预测方法并不能很好地解决问题，因此科学家们开始用智能计算的方法来进行时间序列的预测。
1.2.2 模糊神经网络研究现状
模糊理论起源于控制技术，加州大学伯克利分校自动控制系Zadeh教授于1965年首次提出了模糊集(Fuzzy set)的思想，奠定了模糊控制的基础，又于1973年提出了一型模糊控制系统可以应用于控制领域，在1975年提出了二型模糊集(Type-2 fuzzy set, T2 FS)；1974年伦敦大学的Mamdani博士首次成功地将一型模糊系统应用于锅炉和蒸汽机的控制[7]，从而开创了模糊控制的历史；1976年丹麦Blue Circle Cement and SIRA公司开发了一个水泥窖模糊控制系统, 成为第一个工业模糊控制系统[8]；1987年日本仙台地铁成为第一个成功应用模糊控制的大型工程，此后模糊控制技术开始广泛应用于消费品，出现了模糊控制洗衣机、模糊控制空调等。
自1943年McCulloch和Pitts提出了神经元的数学模型以来，神经网络的研究在陷入了长期的低谷。20世纪80年代，由于参数更新算法的发展，人工神经网络的研究开始进入高潮，一些著名学者断言，基于模糊逻辑与神经网络技术相结合的模糊神经网络将成为21世纪的核心技术。1987年，BartKosko[12]中率先将模糊理论和神经网络有机结合进行了较为系统的研究。在这之后的时间里，模糊神经网络的理论及其应用获得了飞速的发展，各种新的模糊神经网络模型的提出及与其相适应的学习算法的研究不仅加速了模糊神经理论的完善，而且在实践中也得到了非常广泛的应用。

模糊神经网络结合了模糊系统和神经网络的优点，不仅具有通过学习逼近任意非线性映射的能力，使其在非线性系统建模上不受非线性模型类的限制，而且具有思维和推理等深度智能能力，使其在非线性系统建模上能够表达认知不确定性下的推理机制，体现出高度灵活性。模糊神经网络这种将神经网络和模糊逻辑有机融合而产生的新型网络模型，能够提供更加有效的智能行为、学习能力、自适应特点、并行机制和高度灵活性，成为实现模式识别、信号处理、系统辨识、函数逼近等功能的有效手段之一，在预测领域它也扮演了至关重要的角色而备受瞩目。何婷婷开发了一种基于模糊逻辑和神经网络的电池容量预测方法【】。Utkarsh Nigam等人采用模糊神经网络进行艾哈迈达巴德的降雨预测和水文的建模分析。Yuanyuan Gong等人采用模糊神经网络进行金融时间序列局部预测算法的优化。叶霞等人利用模糊神经网络建立了乘用车空调系统模型，对空调性能具有高精度的预测效果。Akhtar等人用模糊推理的方法预测月平均发电量，其结果可以用于微电网、智能电网应用[9]。Czarnowski等人提出了基于相似度和模糊c均值聚类的神经网络结构并验证了其有效性[10]。Wilamowski等人用极限学习机、误差修正算法训练神经网络并进行了比较研究[5]。
利用模糊神经网络的方法不需要构建有关数据分布的数学模型，只需要通过监督学习来对训练集进行数据建模，就可以获得良好的预测效果。虽然单一的基于模糊神经网络的预测算法能够取得较好的预测效果，但是存在参数不宜控制，神经元冗余，预测精度不突出，训练时间过长等问题，因此很多的学者对模糊神经网络的非线性系统建模方法做了很多改进，比如乔俊飞等人开发了二阶自组织模糊神经网络（SOG-SASOFNN）进行区域内空气污染物PM2.5时间序列的预测。。。。。。。
虽然改进模糊神经网络的性能已经得到较大的提升，但是如何提升系统建模的响应速度和泛化性仍然是当前研究的重点。







1.3 研究思路及主要工作
本文的主要研究思路是通过对模糊神经网络结构的改变，提升模糊神经网络在时间序列数据建模中的性能指标，并针对含有漂移和移位的时间序列数据，针对性的进行漂移的检测，以提升模糊神经网络的预测性能。
模糊神经网络是一种将模糊规则语义透明性与神经网络学习能力结合的混合方法。在实际应用中，需要解决的两个问题是结构辨识和参数估计[9]。结构识别需要确定模糊规则的规模，参数估计需要确定使系统可靠的模糊规则的参数。
FNN的结构辨识分为离线辨识和在线辨识。离线辨识就是基于整个训练集更新模糊规则和参数，一般采用专家知识和聚类算法生成合适的模糊规则。常用的结构初始化方法就是聚类算法，比如模糊c均值聚类、峰值聚类、减法聚类、k-进邻聚类。然而当前的研究往往针对在线辨识开发自组织算法而忽略了离线辨识在系统建模初期的作用。
另一方面，在线辨识就是根据每一个实时进入的样本进行训练，并实时更新权值参数，这满足了工业中实时控制的要求。在线辨识常用自组织方法，通过一系列结构辨识指标，对神经元的数量进行调整。比如Wu等人提出了动态模糊神经网络和其增强版本广义动态模糊神经网络可以在线进行结构辨识和参数优化，但是系统的泛化性能不佳。韩等人利用各个规则的相对重要性指标实现SOFNN的自组织[10]，并在另一篇文章中利用信息理论的方法自行设计模糊规则，将具有高峰值强度的模糊规则划分为新的规则，对相对互信息较小的模糊规则进行枝剪[11]。但是在线训练的初始阶段，由于没有专家知识干预，需要较长的时间才能辨识至合适的结果，这无疑会提高系统的响应时间。因此有学者利用专家知识对样本进行初始化，然后再送入自组织模糊神经网络进行学习（SOFNN），比如Wang等人设计了一种基于incremental deep pre-training (IDPT)的自生长算法提取有效特征并作为SOFNN的输入[12]，实现了从原始数据中提取深度特征，有效加快了训练的速度。综合考虑离线辨识和在线辨识的特点，为提高训练效果和速度，本文采用聚类算法对训练数据进行初始化。
模糊神经网络参数估计的主要方法有进化法、梯度下降法和二阶算法。其中进化法有效果好，结构适中的优点。 Lin等人将遗传算法和粒子群优化(GA-PSO)训练FNN，设计了空气质量预测系统[13]。Leng等人利用遗传算法来优化SOFNN的参数，但是由于其采用进化学习的方式，计算成本是需要考虑的问题。梯度下降算法虽然具有简单易实现的优点，但是容易陷入局部最小值，Han等人设计了一种具有自适应学习率的梯度下降算法（sofnn-AGA）来更新参数[9]对梯度下降法做了改进。二阶算法具有二阶收敛且收敛速度快的优点应用较为广泛，周等人[21]提出了自适应学习算法完成SOFNN参数的更新(SOFNN-ALA)，可以有效提升泛化能力。Yu等人设计了改进的LM算法可以减少计算量提高计算速度[16]，并在[18][21][24]得到应用。由于LM算法结合了梯度下降法和高斯牛顿法的优点具有较快的收敛速度，本文采用自适应LM算法优化FNN的前置和结果参数。
基于以上分析，在SOFNN-CA的设计中, 首先结合专家知识，由k-means聚类算法生成一个结构简单的初始模型。该模型将专家经验考虑在内，因而可以在接下来的在线训练中节省时间，加快训练速度。在自组织阶段中采用马氏距离指标以增加神经元，减小了计算量。根据神经元放电特性提出密度势能指标实现神经元宽度的自适应调整。最后根据神经元之间相似度大小决定是否合并神经元，最终得到一个结构紧凑泛化性能好的网络。
在数据流中由于环境的改变或者传感器的自然磨损，会导致数据分布变化，造成概念漂移，比如疫情的突然发生导致消费环境改变，从而人们的消费支出大大减弱，而根据之前的数据建立的消费预测模型就会出现较大的误差。学者们将概念漂移分为：突然漂移、增量漂移、逐渐漂移和重复漂移，如图所示：因此如何更好的处理数据流中的概念漂移是SOFNN需要解决的问题，文章【Edwin2011】中提出了用规则年龄检测数据流中的概念漂移，本文结合规则年龄和规则密度对概念漂移进行检测并对规则进行分裂和删除，最终完成漂移数据流的处理。因此在SORFNN-DC的设计中, 首先由mean-shift算法生成初始化模型。该模型自动生成数据的高密度中心，因而可以在接下来的在线训练中节省时间，加快训练速度。在自组织阶段中采用马氏距离指标以增加神经元，减小了计算量。根据神经元漂移指标将发生了漂移的神经元分裂，最终完成漂移数据流的处理，生成回归模型。
1.4 论文的组织安排
论文共分为5章，论文结构如图1-1所示，各章的具体介绍如下：
第1章：绪论。本章首先介绍了时间序列预测的研究背景以及研究意义，同时对基于统计学的时间序列预测技术以及基于模糊神经网络的时间序列预测技术的发展和现状进行了综合阐述。在论文内容和思路方面说明了神经网络在模式识别、组合优化、函数逼近、智能控制、过程建模等方面的成功应用；介绍了模糊理论与神经网络优势结合的产物FNN，及其在当前应用中的遇到的瓶颈；最后给出了论文的组织安排。
第2章：相关概念及理论基础。首先介绍了时间序列预测的相关定义与理论基础，对时间序列数据的定义、表示方法、分类等进行了说明；然后分传统预测方法和智能计算预测方法两类介绍了时间序列数据的预测；最后对数据流的处理方法进行了阐述。

第3章：基于聚类算法的自组织模糊神经网络的非线性系统建模。首先介绍了当前常用的对数据集进行分类的聚类算法，分析了聚类算法在数据预处理方面的优势；并对自组织模糊神经网络的研究现状以及现有自组织机制中的优势和存在的不足进行分析，最后结合了神经元局部场电位和平均放电率设计了新的自组织机制；最后对新的自组织模糊神经网络的性能进行实验验证，并分析与其他算法对比的优势与不足。
第4章：基于均值漂移算法的递归模糊神经网络的漂移数据流处理。首先，介绍了当前时间序列数据在进行预测的过程中存在的数据流漂移和移位的情况，并对该情况产生的影响进行了说明；然后介绍了无需进行预定义聚类个数的mean-shift聚类算法，并说明了该算法在处理漂移数据流的优势；然后介绍了递归模糊神经网络的网络结构和处理数据的优势；其次针对漂移数据流设计了自组织机制，并分析了该自组织方案相对于其他方案的优势和不足；最后说明了如何生成验证该方案的实验数据，并对该方案进行了实验验证。

第5章：总结与展望。总结了本文所提各模型的研究内容和处理方式，并在已有的工作基础上对未来可能的研究方向和方法进行了展望。
第二章相关概念与理论基础
2.1时间序列数据的基本概念
时间序列数据源自人们对自然界的观察，从古人的夜观天象，到现在的通过气象卫星全天候观测气象动态，人类对时间序列的观测从未间断。我们从记录和采集到的时间序列数据中找到规律并利用它，在这个过程中解释时间序列是非常重要的。
2.1.1时间序列的定义
时间序列数据可以来自人类生产和生活的方方面面，从电厂的电力负荷数据，到污水处理厂的污染物数据；从股票市场的股票价格，到金融市场的证券交易量；从一个城市的年平均降雨量，到一个空气污染物中PM2.5的数值；从一个国家的人口出生率，到世界范围内人口数量的变化，这些放放面面的时间序列数据给我们提供了详尽和充分的研究资料。在统计学研究中，记X(1),X(2),…,X(S)是一组时间序列数据，其中X(1)={x_1 (1),x_2 (1),x_3 (1),…,x_n (1)}是时间为1时各个变量的值，n为时间序列数据的变量个数，S为时间序列数据的长度。我们将该时间序列集合划分为D个数据点的训练集X(1),X(2),…,X(D)和S-D个数据点的测试集X(D+1),X(D+2),…,X(S)，那么对于采用单变量数据的预测模型可以定义为：
x ?(t+1)=f(x(t),x(t-1),……,x(t-N+1)),N≤t<S
对于采用多变量数据的预测模型可以定义为：
x ?_n (t)=f(x_1 (t),x_2 (t),……,x_(n-1) (t)),0<t<S
通过以上数学模型可以发现，单变量预测模型是采用同一变量过去的数据预测该变量将来的值，而多变量数据预测模型是采用同一时刻不同变量的值来预测同一系统内相关变量的值。
2.1.2时间序列的特性
2.1.2.1平稳性
时间序列总体上可以分为平稳时间序列和不平稳时间序列。而对于平稳性的判断有两种，分别是严平稳时间序列和宽平稳时间序列，一般可以采用宽平稳时间序列判别方法来进行序列稳定性判断。宽平稳采用序列的特征统计量来定义要求序列前后的协方差矩阵相等，如果能够保证序列的二阶矩平稳就能保证序列的主要性质近似稳定。
不平稳时间序列是包含一定趋势的时间序列，在传统预测方法中常采用差分的方法将不平稳时间序列转化为平稳时间序列预测。
2.1.2.2周期性
大多数时间序列是存在一定周期性的，比如电网负荷预测中的时间序列，由于企业用电高峰集中在上午，而居民用电高峰一般集中在晚上，因此电网负荷数据呈现一定的周期性，此外以年为周期存在冬季电网负荷高，夏季负荷低的特点。此外某地区的降水量数据也会存在因季节不同而周期性变化的规律。
2.1.2.3随机性
时间序列在大的时间范围内存在周期性，但是在小的时间范围内存在随机性，由于人们生产生活的不确定性以及采集过程中噪声的干扰，时间序列数据在小范围内存在随机性，如电网负荷数据中每个电网用户对电量的需求是不同的，因此电符合的数据总是在一定范围内波动。
2.1.2.4连续性
时间序列按照采集方式的不同可以分为连续时间序列和离散时间序列。连续时间序列中的数据为一个时间段内连续产生的所有值。离散时间序列为间隔一定的时间采集到的不连续的值。


2.2时间序列预测的常用方法
时间序列预测方法主要分为传统预测方法和基于机器学习的预测方法，传统预测方法基于统计学的原理进行预测，对线性系统预测效果比较好，其中最具代表性的是Box-Jenkins法和指数平滑法，这些方法主要利用时间序列本身的信息，对其进行平稳化、差分、自回归、移动平均等处理，得到一个合适的数学模型，然后用该模型进行预测。基于机器学习的预测主要利用时间序列与其他相关变量之间的关系，通过建立复杂的函数关系或者学习算法，来捕捉时间序列的内在特征和动态变化，然后用该函数或算法进行预测。
此外还有组合预测方法，主要是将多种预测方法结合起来综合分析进行预测。
2.2.1传统时间序列预测方法
Box-Jenkins法：
该方法不考虑其他因素对预测变量的影响，实现过程简单，主要通过历史数据对预测变量与时间之间的关系进行建模，然后对变量未来的值进行预测。该方法的模型为：
y_i-a_1 y_(i-1)-…-a_n y_(i-n)=γ_i-b_1 γ_(i-1)-…-b_n γ_(i-n)
其中y_i是观测值，a_1,a_2,…,a_i,b_1,b_2,…,b_i是常数项，γ_1,γ_2,…,γ_(t-n)为白噪声序列，在上式中加入一个延迟项A，则上式写为：
a(A)y_i=b(A)γ_i
上式的三种代表性模型如下：
（1）自回归法：
y_i-a_1 y_(i-1)-…-a_n y_(i-n)=γ_i
自回归模型将i时刻的变量值与i-1至i-n时刻之间的变量值关系表示为线性关系。建立的是i时刻变量值与i时刻之前的一段时间内变量值的模型，当这两个时间段变量值差异过大时，自回归模型取得的预测结果往往较差，因此，自回归模型可用于对变量模型做一个简单初步的估计。
（2）滑动平均法：
y_i-b_1 γ_(i-1)-…-b_n γ_(i-n)=γ_i
滑动平均法拟合了预测变量与白噪声序列之间的关系，而不是考虑预测变量与历史值之间的关系，由上式可以看出预测变量与噪声之间为线性关系。
（3）自回归移动平均法：
y_i-a_1 y_(i-1)-…-a_n y_(i-n)+b_1 γ_(i-1)+?+b_n γ_(i-n)=γ_i
自回归移动平均法将预测变量与历史值的关系考虑在内，又将预测变量与噪声的关系考虑在内，综合了自回归法和滑动平均法的优势，因此取得的效果最好，是目前应用最为普遍的一种方法。
指数平滑法：
指数平滑法根据平滑次数的不同分为一次指数平滑、二次指数平滑、三次指数平滑，指数平滑法是在移动平均法基础上发展起来的一种分析方法，需要计算指数平滑值配合一定的时间序列预测模型对现象的未来进行预测，原理是任一期的指数平滑值都是本期实际观察值与前一期指数平滑值的加权平均。一次指数平滑预测公式为：
 
式中y ?_(t+1)为t+1时刻的预测值，又为t时刻的平滑值；y_t为t时刻的实际值；y ?_t为t时刻的预测值，又为t-1时刻的平滑值；α为平滑常数，取值范围为【0,1】。由于指数平滑法在实际计算的时候只需要两个数值，即y_t和y ?_t，因此具有逐期递推性质，给预测带来了较大的方便。
2.2.2基于机器学习的预测方法
基于机器学习的时间序列预测方法较为常用于非线性时间序列预测领域，由于神经网络和混沌理论的发展，非线性时间序列预测的准确度也越来越高，常用的预测方法有：回归分析、支持向量机、神经网络、隐马尔科夫模型。

2.2.2.1回归分析
回归分析拟合预测变量与其相关因子之间关系的数学模型，而相关的因子可以是时间、天气、温度等环境数据，也可以是其他相关变量的数据，由于大多数时间序列都是非线性的，因此常用数学方法将其转化为线性模型，比如下式所示：
y=a_1 x_1+a_2 x_2+?+a_n x_n+b
y表示预测的变量，x表示输入的相关变量，a表示系数，b为固定值。
该方法的预测过程通常采用最小二乘法对历史数据进行建模，最小二乘法的基本思想是使系统实际输出与估计输出（带有估计参数的系统的输出）的偏差（残差）的平方和最小，然后用拟合得到的系数对未来数据进行预测。
2.2.2.2支持向量机
支持向量机（SVM）是一类按监督学习方式对数据进行二元分类的广义线性分类器，最早由Vladimir Vapnik于1964年提出求解线性问题，后来到1992年基于核函数的SVM被提出，才用来解决非线性问题，其决策边界是对学习样本求解的最大边距超平面，可以将问题化为一个求解凸二次规划的问题。与逻辑回归和神经网络相比，支持向量机，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。
支持向量机的拓扑结构如图所示：
 
SVR的主要目标是寻找一个最优超平面w?x+b=0，使得所有样本点到超平面的距离最大。但对于SVR线性回归问题而言，问题则变为寻求一个最优超平面，使得在给定精度条件下可以在允许误差范围内拟合预测变量；对于非线性回归问题而言，可以通过核函数变换将样本映射到一个高维空间中从而使得问题变得线性可分。
SVR性能的优劣在很大程度上取决于核函数类型和核函数参数的确定，常见的核函数有线性核函数、多项式核函数、高斯核函数、拉普拉斯核函数、Sigmoid核函数，不同的核函数对应不同的映射方式。
线性核函数：K(x,y)=x?y。
多项式核函数：K(x,y)=[g(x?y)+c]^d，其中g，c，d为参数。其实，线性核函数为多项式核函数的一种特殊形式。
高斯核函数：又称为径向基核函数，其表达为K(x,y)=exp(-‖x-y‖^2?(2σ^2 ))，其中σ为参数。
拉普拉斯核函数：K(x,y)=exp(-‖x-y‖?σ)，其中σ为参数。
Sigmoid核函数：K(x,y)=tanh(g(x?y)+c)，其中g，c为参数。
对于核函数的选取，不同的核函数得到的最后的结果会相差很大，一般情况下高斯核函数的效果要优于线性核函数和多项式核函数，但是计算量会大很多，因此选择核函数应该具体问题具体分析。
2.2.2.3神经网络
（1）Bp神经网络
BP神经网络是根据人类大脑的学习、决策机制而建立的一套理论体系，它具有强大的计算、自学习、推理能力。Rumelhart与 McCelland在《并行分布式处理》中详细阐述了 BP神经网络的原理及其实现过程，并展望了其潜在能力，使得BP神经网络在上世纪八十年代广泛传播开来。BP神经网络通过非线性函数作为变换函数，赋予了隐含层学习能力，因此能对任意的输入通过学习训练以后来产生较为理想的输出响应。BP神经网络是目前应用最广泛的神经网络，广泛应用于预测、分类、故障诊断等问题中，并取得了良好效果。每个神经网络的隐含层层数不同，需要根据具体问题来具体分析，目前还没有统一的理论加以指导。如下图所示：为bp神经网络的结构图
 
该神经网络的优势在于它是由非线性变换单元组成的基于误差反向传播算法的多层前馈型网络，它一般分为输入层、隐含层（隐含层可以由一层或多层构成）和输出层组成，每层又包括若干个神经元，每层神经元的输出经特定的激励函数只影响下层神经元的输入，同层神经元之间互不影响。
由上图可以看出BP神经网络就类似于一个非线性函数，输入为相关变量，输出为预测变量。学习过程分为信息的正相传播和反向传播。首先让输入信息在初始权值、阈值的作用下经输入层、隐含层的神经元传递到输出层，若输出结果和期望结果的误差大于给定精度时，则转入反向传播过程，并修正各层的权值和阈值，使误差减少，如此反复迭代，当输出结果和期望值的误差达到允许精度时，则停止训练，输出最终结果。
网络的前向传播过程为：
隐层神经元的输入为所有输入的加权和，
x_j=∑_i?〖ω_ij x_i 〗
隐层神经元的输出为x ?_j由Sigmoid函数激发x_j，得
x ?_j=f(x_j )=1/(1+e^(〖-x〗_j ) )
输出层神经元的输出为：
y=∑_j?〖ω_jo x ?_j 〗
最后反向传播过程采用梯度下降法更新输出层和隐含层的权值参数。
权值更新为：
 
BP神经网络比早期的一些人工神经网络有着更成熟的网络结构，因此能够以任意精度逼近非线性模型，此外还有有自学习和自适应能力，也有较好的泛化能力和容错能力，在时间序列预测中被广泛使用，但是它也存在一些问题。比如局部最小值问题，由于bp神经网路一般采用梯度下降法来更新网络的权值参数，这种算法是一种局部搜索优化方法收敛速度慢且容易陷入局部最小值，从而导致网络训练失败。另外BP神经网络结构的大小完全由开发人员的经验确定，因此很容易导致网络神经元的冗余或者短缺。
（2）Rbf神经网络
RBF神经网络的结构为：
 
RBF神经网络是由J.Moody和C.Darken于20世纪80年代提出的一种神经网络，在图中可以看到它是具有单隐层的三层前馈网络。RBF网络模拟了人脑中局部调整、相互覆盖接收域的神经网络结构，是针对BP网络收敛速度慢且容易陷入局部最小值而提出的改进型网络，与BP神经网络不同的是网络隐含层使用的是高斯基函数而非Sigmoid函数，高斯基函数在输入空间中有限范围内为非零值，因而rbf神经网络是一种局部逼近的网络。由于该网络在计算过程中输入到输出的映射是非线性的，而隐含层到输出空间的映射是线性的，使得该网络避免了繁琐冗长的计算，具有较高的运算速度和自适应性。
RBF网络的结构图由上图所示：
在神经网络的输入层到隐含层是不包含权值的，因此输入变量为x={x_1,x_2,x_3,…,x_n }，隐含层神经元的输出为：
h_j=exp(-‖x-c_j ‖^2/(2b_j^2 )),j=1,2,…,m
其中c_j=[c_j1,…,c_jn ]为第j个隐层神经元的中心点向量值。b=[b_1,…b_j,…,b_m ],b_j>0,为高斯基函数的宽度向量。
网络的权值为：
ω=[ω_1,…ω_j,…,ω_m ]
RBF网络的输出为：
y_m (t)=ω_1 h_1+ω_2 h_2+??+ω_m h_m
由于RBF网络只调节权值，因此，rbf网络较ＢＰ网络有结构简单、运算快速的优点。

（３）Elman神经网络
Elman神经网络的结构为：
 
Elman网络的最早由美国加州大学圣地亚哥分校认知科学系教授Jeffrey L. Elman在1990年发表的文章《Finding structure in time》中提出。Elman网络是一种典型的动态神经网络，在语音处理和时间序列预测问题上应用较多，它是在BP网络的结构上，在隐含层增加了一个承接层或称递归层作为延时算子，用于记忆隐层过去的状态，并在下一时刻连同网络输入一起作为隐含层的输入，从而使系统具有适应时变特性的能力。由于递归层的加入，Elman网络相比于BP神经网络更为适合建立时间序列预测模型。
Elman网络的输入为
(&y(k)=g(w^3 x(k))@&x(k)=f(w^1 x_c (k)+w^2 (u(k-1)))@&x_c (k)=x(k-1))
Elman网络结构简单高效，由于递归层的存在，无需存储所有的输入信息就能反应出历史信号对当前系统的影响。在计算能力和网络稳定性上比BP网络更好，但与BP神经网络一样，算法都是采用基于梯度下降法，会出现训练速度慢和容易陷入局部极小点的缺点，对神经网络的训练较难达到全局最优。
（４）模糊神经网络
模糊神经网络结合了模糊规则和神经网络的优点，模糊规则可以很好的将专家经验转化为计算机可以识别的语言，而神经网络可以很方便的完成非线性映射，因此模糊神经网络能够更加高效快捷的进行时间序列数据的处理。对于非线性时间序列数据，我们定义的模糊神经网络分为输入层、隶属函数层、规则层和输出层。其网络结构将在下文中介绍。

2.2.2.4隐马尔科夫模型
隐马尔科夫模型是统计模型，被用来描述一个含有隐含未知参数的马尔科夫过程，其难点是从可观察的参数中确定该过程的隐含参数，然后利用这些参数来作进一步分析，例如模式识别，时间序列预测等。
隐马尔科夫模型为一个五元组(Ω_X,Ω_o,A,B,Π)，其中Ω_X={q_1,q_2,…,q_N }为隐状态集合，可以表示一个系统的真实状态；Ω_o={v_1,v_2,…,v_N }为观察值集合，一般表示过程中的可见状态；Π=π_i为初始状态概率矩阵包含了模型在初始状态下各个隐状态的概率；A=(a_ij )为状态转移概率P(x_(j_t )│x_(i_(t-1) ) )的矩阵，包含了由一个隐状态到另一个隐状态的概率；B=(b_ij )为输出概率P(y_j│x_i )矩阵，包含了给定隐状态下的观察到某个观察状态的概率。
在处理时间序列数据时，模型的训练是在已知观察值集合和隐状态集合时，利用这两矩阵进行参数估计，学习出状态转移概率矩阵A和输出概率矩阵B。此外针对不同的问题隐马尔科夫模型还有不同的求解算法如前向算法、viterbi算法、Baum--Welch算法。但是该模型的缺点在于隐状态的个数是事先指定的，无法根据动态的时间序列数据进行动态变化，不利于预测效果的提升。
（说一下它的缺点）

